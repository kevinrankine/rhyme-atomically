{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.model.ngram import LaplaceNgramModel\n",
    "from nltk.model.ngram import MLENgramModel\n",
    "from nltk.model.ngram import LidstoneNgramModel\n",
    "from nltk.model import count_ngrams\n",
    "from nltk.model import build_vocabulary\n",
    "import kenlm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus = 'data/50-cent.txt'\n",
    "#lm_file = 'data/50-cent.klm'\n",
    "\n",
    "corpus = 'data/processed-lyrics.txt'\n",
    "lm_file = 'data/lyrics.klm'\n",
    "\n",
    "#corpus = 'data/chief-keef.txt'\n",
    "#lm_file = 'data/chief-keef.klm'\n",
    "\n",
    "sentences = map(lambda x : x.split(' '), open(corpus, 'r').read().split('\\n'))\n",
    "text = [val for sub in sentences for val in sub]\n",
    "text = filter(lambda x : x != '', text)\n",
    "\n",
    "vocab = build_vocabulary(1000, text)\n",
    "# counter = count_ngrams(2, vocab, sentences)\n",
    "# model = MLENgramModel(counter)\n",
    "model = kenlm.Model(lm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151751\n",
      "a shit nigga \n",
      " he ate off the body \n",
      " you feel nigga do or die \n",
      " then she left you gon put em down like a comet \n",
      " 80 karats in my pocket \n",
      " you closed the cheeks \n",
      " your favorite rapper ice and watch his slaughterhouse im alterior \n",
      " boi im still weed crumpling \n",
      " step and get stoned \n",
      " i know the legendary  i aint really real i can see the one line and thats bitch gainer without puttin slugs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = vocab.keys()\n",
    "print len(words)\n",
    "\n",
    "context = 'a shit nigga'\n",
    "sent = context\n",
    "word = ''\n",
    "ii = 0\n",
    "jj = 0\n",
    "\n",
    "while ii < 10:\n",
    "    scores = np.array(map(lambda word : 10 ** model.score(context + ' ' + word, bos=False, eos=False), words))\n",
    "    scores = scores / np.sum(scores)\n",
    "    \n",
    "    word = np.random.choice(words, p=scores)\n",
    "    \n",
    "    index = np.argmax(scores)\n",
    "    max_word = words[index]\n",
    "    \n",
    "    '''\n",
    "    if max_word == '<nl>':\n",
    "        word = '<nl>'\n",
    "    \n",
    "    while word == '<nl>' and jj < 8:\n",
    "        word = np.random.choice(words, p=scores)\n",
    "    '''\n",
    "    '''\n",
    "    if scores.max() > 0.7 and max_word == '<nl>':\n",
    "        word = '<nl>'\n",
    "    '''\n",
    "        \n",
    "    context = ' '.join(context.split()[1:] + [word])\n",
    "    sent = sent + ' ' + word\n",
    "    \n",
    "    if word == '<nl>':\n",
    "        ii = ii + 1\n",
    "        jj = -1\n",
    "    \n",
    "    jj = jj + 1\n",
    "    \n",
    "sent = sent.replace('<nl>', '\\n')\n",
    "sent = sent.replace('<nv>', '')\n",
    "\n",
    "print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
